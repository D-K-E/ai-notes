{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04816074-23c5-4d69-bc44-752681345380",
   "metadata": {},
   "source": [
    "# Camera Motion\n",
    "\n",
    "Camera motion refers to change in camera SE3 (see Lie-Group-Algebra) from available information.\n",
    "There are 3 types of information that can be used for estimating camera motion:\n",
    "\n",
    "- Monocular camera case: We try to estimate the camera motion using sets of 2d points.\n",
    "- Binocular camera or RGB-D camera case: We try to estimate the camera motion using sets of 3D points\n",
    "- Mixed case: We have a 3D set of points and their 2D projections. We try to estimate the camera pose using these two elements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabd7d42-9b98-434a-879a-17cd4df363c4",
   "metadata": {},
   "source": [
    "## Monocular camera\n",
    "\n",
    "Estimating camera motion from monocular camera requires some knowledge on epipolar geometry.\n",
    "\n",
    "Let's define the problem. Given a spatial position $P = [x, y, z]$, and a set of images $I_1, I_2,... , I_i,  ..., I_n$,\n",
    "the pixel position of $P$ in $I_i$ is $p_i$.\n",
    "We know that $s_i * p_i = K * (R(i) * P + t(i))$, where $R$ is rotation matrix and $t$ is the translation vector at $i$th point in time, and $K$ represents the intrinsic camera matrix. \n",
    "\n",
    "Now, we know that in homogenous coordinates a vector is equal to itself when multiplied by a non zero constant, so in a homogenous coordinate system $s_i v_i = v_i$. This type of equality is called: *equal up to scale*. \n",
    "We say for example that $s_i v_i$ is equal up to a scale with $v_i$. Why both are considered equal ?\n",
    "Well they still express the same transformation: $A = [x=2 * 2, y=2 * 3, z=2 * 4, w=2 * 1]$ when we do a transformation from 4d - 3d with $A / w$, we get $A = [x=2, y=3, z=4]$. \n",
    "If we didn't do the multiplication with $2$, we would still get the same result.\n",
    "\n",
    "Let's express the equality as $s_i v_i \\simeq v_i$.\n",
    "The relationship is $$p_i \\simeq K * (R(i) * P + t(i))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b77689c-cc45-43ac-a073-c34ca401850a",
   "metadata": {},
   "source": [
    "Now, let's remove intrinsic properties of camera from the equation: $$x_i = p_i K^{-1}$$\n",
    "Here, the sequential nature of images matter, because it binds the $x_i$ to $x_{i+1}$ through rotation and translation. \n",
    "Remember that the spatial position of $P$ is the same, the only thing that changes is the camera pose, and camera pose is described by rotation + translation in world coordinate.\n",
    "Hence $$x_i \\simeq R_{i}x_{i-1} + t_{i}$$\n",
    "\n",
    "If we multiply both sides with $x_i^T t_i\\hat{}$, we get an interesting result:\n",
    "$$x_i^T t_i\\hat{} x_i \\simeq x_i^T t_i\\hat{} R_i x_{i-1} + x_i^T t_i\\hat{} t_i$$\n",
    "\n",
    "The transposition in $x_i^T$ is actually necessary to make the matrix multiplication work on both sides.\n",
    "\n",
    "Now the $t_i\\hat{} x_i$ is simply the cross product of $t_i$ and $x_i$ (since $t_i\\hat{}$ is the skew-symmetric matrix). \n",
    "\n",
    "Given that cross product produces a vector that is orthogonal to each of its multipliers, the inner product of $x_i^T$ with the resulting vector would necessarily be 0: $$0 \\simeq x_i t_i\\hat{} R_i x_{i-1} + x_i t_i\\hat{} t_i$$\n",
    "\n",
    "Here the $t_i\\hat{} t_i$ is also 0, as can be seen from the snippet below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c99fb2a5-3893-4d06-abf0-cd79f2a9c7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "xi = np.array([1,2,3], dtype=float)\n",
    "x_p = np.array([[0, -3, 2],\n",
    "                [3, 0, -1], \n",
    "                [-2, 1, 0]], dtype=float)\n",
    "\n",
    "print(xi.T.dot(x_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73beaeb3-26bd-49d4-8d81-87f9e7fb1e90",
   "metadata": {},
   "source": [
    "Then we are left with the following equation $$0 \\simeq x_i^T t_i\\hat{}R_i x_{i-1} + 0$$\n",
    "\n",
    "Now, since no scalar multiplication would change what is going to happen at the left side of the equation, it makes very little sense to conserve the constraint $\\simeq$ on the equation. \n",
    "Hence we end up with: $$x_i^T t_i\\hat{}R_i x_{i-1} = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d283bb-f5f0-4100-b3b6-a8dc122895e7",
   "metadata": {},
   "source": [
    "This constraint is known as the epipolar constraint. \n",
    "If we add the pixel coordinates back to the equation: $$p_i^T K^{-T}t_i\\hat{}R_i p_{i-1}K^{-1} = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca21bf2-0d24-415e-be6e-8b87371bb5b4",
   "metadata": {},
   "source": [
    "The matrix $t_i\\hat{}R_i$ is called the *essential* matrix: $E = t_i\\hat{}R_i$.\n",
    "\n",
    "Under the epipolar constraint the problem looks like the following: \n",
    "$x_i = [u_i, v_i, 1]$, $x_{i-1} = [u_{i-1}, v_{i-1}, 1]$\n",
    "$$[u_i, v_i, 1] \\begin{pmatrix} e_1 & e_2 & e_3 \\\\ e_4 & e_5 & e_6 \\\\ e_7 & e_8 & e_9 \\end{pmatrix} [u_{i-1}, v_{i-1}, 1]^T = 0$$  \n",
    "\n",
    "If we actually do the multiplication, we end up with:\n",
    "$$[u_i, v_i, 1] [u_{i-1} * e_1 + v_{i-1} * e_2 + 1 * e_3, \n",
    "   u_{i-1} * e_4 + v_{i-1} * e_5 + 1 * e_6,\n",
    "   u_{i-1} * e_7 + v_{i-1} * e_8 + 1 * e_9] = 0$$\n",
    "\n",
    "$$[u_i(u_{i-1} * e_1 + v_{i-1} * e_2 + 1 * e_3) \n",
    "  + v_i(u_{i-1} * e_4 + v_{i-1} * e_5 + 1 * e_6)\n",
    "  + u_{i-1} * e_7 + v_{i-1} * e_8 + 1 * e_9] = 0$$\n",
    "  \n",
    "$$[u_i * u_{i-1} * e_1 + u_i * v_{i-1} * e_2 + u_i * e_3\n",
    "   + v_i * u_{i-1} * e_4 +v_i * v_{i-1} * e_5 + v_i * e_6\n",
    "   + u_{i-1} * e_7 + v_{i-1} * e_8 + 1 * e_9 = 0$$\n",
    "   \n",
    "$$[u_i * u_{i-1}, u_i * v_{i-1}, u_i, v_i * u_{i-1}, v_i * v_{i-1}, \n",
    "   v_i, u_{i-1}, v_{i-1}, 1] \\cdot \n",
    "   [e_1, e_2, e_3, e_4, e_5, e_6, e_7, e_8, e_9] = 0$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fd9db4-e7ba-420b-80f8-5b50da28a35b",
   "metadata": {},
   "source": [
    "## Mixed case: Perspective n Point method\n",
    "\n",
    "We obtained the 3D position of a point in camera space using RGB-D camera or using binocular camera, we also know consequently their 2d projection positions.\n",
    "Perspective n Point (PNP) method concerns how to estimate camera's pose (rotation translation in world coordinate) from this information.\n",
    "\n",
    "There are essentially two methods, direct linear transformation (DLT) and bundle adjustment (BA). Let's see DLT first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cdbcc4-fff6-43e4-a49c-b30bc9e94a53",
   "metadata": {},
   "source": [
    "### Direct Linear Transformation (DLT)\n",
    "\n",
    "We have point in 3D space: $P = [x,y,z]$ in homogenous coordinates: $P = [x, y, z, 1]$. \n",
    "The projected P is $p = [u, v, 1]$.\n",
    "From 3d math we know that:\n",
    "$$s [u, v, 1] = \\begin{pmatrix} t_1 & t_2 & t_3 & t_4 \\\\ t_5 & t_6 & t_7 & t_8 \\\\ t_9 & t_{10} & t_{11} & t_{12} \\end{pmatrix} [x, y, z, 1]$$\n",
    "\n",
    "This is a matrix with 12 unknowns, so given 6 pairs of matching points, this can be solved using QR decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597ead40-41fa-4bcd-a22d-0729262814a8",
   "metadata": {},
   "source": [
    "### Bundle Adjustment (BA)\n",
    "\n",
    "We have point in 3D space: $P = [x,y,z]$ in homogenous coordinates: $P = [x, y, z, 1]$. \n",
    "The projected P is $p = [u, v, 1]$.\n",
    "From 3d math we know that:\n",
    "$$s [u, v, 1] = K T [x, y, z, 1]$$\n",
    "where $K$ is the intrinsic camera matrix, and $T$ is the SE3d from lie algebra.\n",
    "\n",
    "During the calculation of $T$, we assume that given some initial value for $T$, there will be an error between the\n",
    "projected $p$ and the observed $p$. \n",
    "This error comes from the fact that we don't effectively know what $T$ is.\n",
    "The main idea behind BA is to minimize this error using the least square method to obtain a good enough $T$.\n",
    "\n",
    "Formally we try to minimize $f_{loss}(T) = \\frac{1}{2} \\sum_{i=1}^{2} || p_i - \\frac{1}{s} KTP$ where $p_i$ is either $u$ or $v$.\n",
    "Notice that $K$ doesn't change and $P$ doesn't change as we change $p$. \n",
    "Hence we try to find the $T$ using available $p$s by minimizing the least square loss function above.\n",
    "\n",
    "The usual way to minimize/maximize a function to achive the following ordering $f_{loss}(T + \\nabla T) < f_{loss}(T)$ is to $\\nabla T = -J(T)$, meaning that take the opposite of the first order derivative and add it to the argument. \n",
    "\n",
    "The Non-linear-Optimization notebook expands upon this idea. \n",
    "The Gauss-Newton equation adapts to our problem like the following:\n",
    "$$J(T)J^T(T) \\nabla T = -J(T)f_{loss}(T)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c237d5-2d5b-47e1-bdb5-fced1d1cbd35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
