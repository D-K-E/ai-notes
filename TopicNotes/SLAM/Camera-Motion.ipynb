{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04816074-23c5-4d69-bc44-752681345380",
   "metadata": {},
   "source": [
    "# Camera Motion\n",
    "\n",
    "Camera motion refers to change in camera SE3 (see Lie-Group-Algebra) from available information.\n",
    "There are 2 main approaches:\n",
    "\n",
    "- Feature matching based methods\n",
    "- Optical Flow based methods\n",
    "\n",
    "We'll start with feature matching based methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ad84f6-95b4-4a47-9e15-be3d1d1443ff",
   "metadata": {},
   "source": [
    "## Feature Based Camera Motion Estimation\n",
    "\n",
    "\n",
    "There are 3 types of information that can be used for estimating camera motion in feature based methods:\n",
    "\n",
    "- Monocular camera case: We try to estimate the camera motion using sets of 2d points.\n",
    "- Binocular camera or RGB-D camera case: We try to estimate the camera motion using sets of 3D points\n",
    "- Mixed case: We have a 3D set of points and their 2D projections. We try to estimate the camera pose using these two elements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabd7d42-9b98-434a-879a-17cd4df363c4",
   "metadata": {},
   "source": [
    "### Monocular camera\n",
    "\n",
    "Estimating camera motion from monocular camera requires some knowledge on epipolar geometry.\n",
    "\n",
    "Let's define the problem. Given a spatial position $P = [x, y, z]$, and a set of images $I_1, I_2,... , I_i,  ..., I_n$,\n",
    "the pixel position of $P$ in $I_i$ is $p_i$.\n",
    "We know that $s_i * p_i = K * (R(i) * P + t(i))$, where $R$ is rotation matrix and $t$ is the translation vector at $i$th point in time, and $K$ represents the intrinsic camera matrix. \n",
    "\n",
    "Now, we know that in homogenous coordinates a vector is equal to itself when multiplied by a non zero constant, so in a homogenous coordinate system $s_i v_i = v_i$. This type of equality is called: *equal up to scale*. \n",
    "We say for example that $s_i v_i$ is equal up to a scale with $v_i$. Why both are considered equal ?\n",
    "Well they still express the same transformation: $A = [x=2 * 2, y=2 * 3, z=2 * 4, w=2 * 1]$ when we do a transformation from 4d - 3d with $A / w$, we get $A = [x=2, y=3, z=4]$. \n",
    "If we didn't do the multiplication with $2$, we would still get the same result.\n",
    "\n",
    "Let's express the equality as $s_i v_i \\simeq v_i$.\n",
    "The relationship is $$p_i \\simeq K * (R(i) * P + t(i))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b77689c-cc45-43ac-a073-c34ca401850a",
   "metadata": {},
   "source": [
    "Now, let's remove intrinsic properties of camera from the equation: $$x_i = p_i K^{-1}$$\n",
    "Here, the sequential nature of images matter, because it binds the $x_i$ to $x_{i+1}$ through rotation and translation. \n",
    "Remember that the spatial position of $P$ is the same, the only thing that changes is the camera pose, and camera pose is described by rotation + translation in world coordinate.\n",
    "Hence $$x_i \\simeq R_{i}x_{i-1} + t_{i}$$\n",
    "\n",
    "If we multiply both sides with $x_i^T t_i\\hat{}$, we get an interesting result:\n",
    "$$x_i^T t_i\\hat{} x_i \\simeq x_i^T t_i\\hat{} R_i x_{i-1} + x_i^T t_i\\hat{} t_i$$\n",
    "\n",
    "The transposition in $x_i^T$ is actually necessary to make the matrix multiplication work on both sides.\n",
    "\n",
    "Now the $t_i\\hat{} x_i$ is simply the cross product of $t_i$ and $x_i$ (since $t_i\\hat{}$ is the skew-symmetric matrix). \n",
    "\n",
    "Given that cross product produces a vector that is orthogonal to each of its multipliers, the inner product of $x_i^T$ with the resulting vector would necessarily be 0: $$0 \\simeq x_i t_i\\hat{} R_i x_{i-1} + x_i t_i\\hat{} t_i$$\n",
    "\n",
    "Here the $t_i\\hat{} t_i$ is also 0, as can be seen from the snippet below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c99fb2a5-3893-4d06-abf0-cd79f2a9c7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "xi = np.array([1,2,3], dtype=float)\n",
    "x_p = np.array([[0, -3, 2],\n",
    "                [3, 0, -1], \n",
    "                [-2, 1, 0]], dtype=float)\n",
    "\n",
    "print(xi.T.dot(x_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73beaeb3-26bd-49d4-8d81-87f9e7fb1e90",
   "metadata": {},
   "source": [
    "Then we are left with the following equation $$0 \\simeq x_i^T t_i\\hat{}R_i x_{i-1} + 0$$\n",
    "\n",
    "Now, since no scalar multiplication would change what is going to happen at the left side of the equation, it makes very little sense to conserve the constraint $\\simeq$ on the equation. \n",
    "Hence we end up with: $$x_i^T t_i\\hat{}R_i x_{i-1} = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d283bb-f5f0-4100-b3b6-a8dc122895e7",
   "metadata": {},
   "source": [
    "This constraint is known as the epipolar constraint. \n",
    "If we add the pixel coordinates back to the equation: $$p_i^T K^{-T}t_i\\hat{}R_i p_{i-1}K^{-1} = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca21bf2-0d24-415e-be6e-8b87371bb5b4",
   "metadata": {},
   "source": [
    "The matrix $t_i\\hat{}R_i$ is called the *essential* matrix: $E = t_i\\hat{}R_i$.\n",
    "\n",
    "Under the epipolar constraint the problem looks like the following: \n",
    "$x_i = [u_i, v_i, 1]$, $x_{i-1} = [u_{i-1}, v_{i-1}, 1]$\n",
    "$$[u_i, v_i, 1] \\begin{pmatrix} e_1 & e_2 & e_3 \\\\ e_4 & e_5 & e_6 \\\\ e_7 & e_8 & e_9 \\end{pmatrix} [u_{i-1}, v_{i-1}, 1]^T = 0$$  \n",
    "\n",
    "If we actually do the multiplication, we end up with:\n",
    "$$[u_i, v_i, 1] [u_{i-1} * e_1 + v_{i-1} * e_2 + 1 * e_3, \n",
    "   u_{i-1} * e_4 + v_{i-1} * e_5 + 1 * e_6,\n",
    "   u_{i-1} * e_7 + v_{i-1} * e_8 + 1 * e_9] = 0$$\n",
    "\n",
    "$$[u_i(u_{i-1} * e_1 + v_{i-1} * e_2 + 1 * e_3) \n",
    "  + v_i(u_{i-1} * e_4 + v_{i-1} * e_5 + 1 * e_6)\n",
    "  + u_{i-1} * e_7 + v_{i-1} * e_8 + 1 * e_9] = 0$$\n",
    "  \n",
    "$$[u_i * u_{i-1} * e_1 + u_i * v_{i-1} * e_2 + u_i * e_3\n",
    "   + v_i * u_{i-1} * e_4 +v_i * v_{i-1} * e_5 + v_i * e_6\n",
    "   + u_{i-1} * e_7 + v_{i-1} * e_8 + 1 * e_9 = 0$$\n",
    "   \n",
    "$$[u_i * u_{i-1}, u_i * v_{i-1}, u_i, v_i * u_{i-1}, v_i * v_{i-1}, \n",
    "   v_i, u_{i-1}, v_{i-1}, 1] \\cdot \n",
    "   [e_1, e_2, e_3, e_4, e_5, e_6, e_7, e_8, e_9] = 0$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fd9db4-e7ba-420b-80f8-5b50da28a35b",
   "metadata": {},
   "source": [
    "### Mixed case: Perspective n Point method\n",
    "\n",
    "We obtained the 3D position of a point in camera space using RGB-D camera or using binocular camera, we also know consequently their 2d projection positions.\n",
    "Perspective n Point (PNP) method concerns how to estimate camera's pose (rotation translation in world coordinate) from this information.\n",
    "\n",
    "There are essentially two methods, direct linear transformation (DLT) and bundle adjustment (BA). Let's see DLT first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cdbcc4-fff6-43e4-a49c-b30bc9e94a53",
   "metadata": {},
   "source": [
    "#### Direct Linear Transformation (DLT)\n",
    "\n",
    "We have point in 3D space: $P = [x,y,z]$ in homogenous coordinates: $P = [x, y, z, 1]$. \n",
    "The projected P is $p = [u, v, 1]$.\n",
    "From 3d math we know that:\n",
    "$$s [u, v, 1] = \\begin{pmatrix} t_1 & t_2 & t_3 & t_4 \\\\ t_5 & t_6 & t_7 & t_8 \\\\ t_9 & t_{10} & t_{11} & t_{12} \\end{pmatrix} [x, y, z, 1]$$\n",
    "\n",
    "This is a matrix with 12 unknowns, so given 6 pairs of matching points, this can be solved using QR decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597ead40-41fa-4bcd-a22d-0729262814a8",
   "metadata": {},
   "source": [
    "#### Bundle Adjustment (BA)\n",
    "\n",
    "We have point in 3D space: $P = [x,y,z]$ in homogenous coordinates: $P = [x, y, z, 1]$. \n",
    "The projected $P$ is $p = [u, v, 1]$.\n",
    "From 3d math we know that:\n",
    "$$s [u, v, 1] = K T [x, y, z, 1]$$\n",
    "where $K$ is the intrinsic camera matrix, and $T$ is a member of $SE(3)$, the $s$ is there to counter the effect of perspective projection.\n",
    "As you may remember projection of $KTP$ to $p$ happens after dividing the all members by the depth, so if we want to make this relationship explicit, we can also write the equation above like:\n",
    "$$KTP_z [u, v, 1] = K T P$$\n",
    "\n",
    "The difference between measured $p$ from feature matching and the projected $p$ obtained from the formula above is called the reprojection error.\n",
    "\n",
    "If we can minimize the reprojection error $w$, we can get:\n",
    "\n",
    "- Camera pose (camera location in world coordinate)\n",
    "- Spatial position of feature points\n",
    "\n",
    "The general strategy for finding minimum and maximum output of any function $f$ usually involves either going opposite to the derivative of the function ($f_{loss}(\\alpha + \\nabla \\alpha) < f_{loss}(\\alpha) | \\nabla \\alpha = f'_{loss}(\\alpha)$) or, solving the case where the function derivative is equal to 0 ($f'_{loss} = 0$).\n",
    "\n",
    "Remember that derivative measures the rate of change of a variable of a function.\n",
    "Now in our equation: $w = ||m_p - (K T P)/ (KTP_z)||^2$ where $m_p$ is the measured $p$, two variables of interest are $T$ which is related to camera pose, and $P$ which is related to spatial position of the point detected by feature matching."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178f99aa-4e5f-4a30-ab42-17b385f85176",
   "metadata": {},
   "source": [
    "These two are the contributing factors to the error $w = [w1, w2, 1]^T$, so it makes sense to derive $w$ against these variables, to see how $w$ changes when we change one of these variables. \n",
    "\n",
    "Formally, we are describing $w$ as the following function: $w = m_p - (K \\cdot T \\cdot P)/ s$ where $K$ and $m_p$ are constants.\n",
    "We are then looking for two partial derivatives:\n",
    "- $\\frac{\\partial w}{T}$\n",
    "- $\\frac{\\partial w}{P}$\n",
    "\n",
    "Remember that $T \\in SE(3)$ so we know that one way of taking its derivative is to use a left perturbation. \n",
    "Hence our first expression $\\frac{\\partial w}{T}$ transforms into\n",
    "$\\frac{\\partial w}{d}$ where $d$ represents the left perturbation of $T$.\n",
    "Then we are know looking for how $w$ changes with respect to $d$.\n",
    "\n",
    "Let $w = f_1(T) = k(g(T))$ where $g(T) = T \\cdot P = P'$ and \n",
    "$k(P') = m_p - (K \\cdot P') / s$, then\n",
    "$$f'_1(T) = \\frac{\\partial w}{d} = \\lim_{d \\to 0} \\frac{f_1(d \\star T) - f_1(T)}{d}$$\n",
    "From the chain rule: $f'_1(T) = k'(g(T)) g'(T)$\n",
    "Then the above equation is simply:\n",
    "$$\\frac{\\partial w}{d} = \\frac{\\partial w}{P'} \\frac{\\partial P'}{d}$$\n",
    "\n",
    "The first part of this equation $\\frac{\\partial w}{P'}$ is relatively simple.\n",
    "Let $P' = [x', y', z']^T$ then \n",
    "$$s * [u, v, 1]^T = K \\cdot P' = \\begin{pmatrix} f_x & 0 & c_x \\\\ 0 & f_y & c_y \\\\ 0 & 0 & 1 \\end{pmatrix} \\cdot [x', y', z']^T$$\n",
    "Simply from this equation, one should note that $s = z'$ (when matrix multiplication is done the last row only consists of $z'$ from here one can see that coefficient $s$ must be equal to projection's depth $z'$)\n",
    "\n",
    "From here it should be easy to see:\n",
    "- $s * u = f_x x' + c_x z' = f_x \\frac{x'}{z'} + c_x$\n",
    "- $s * v = f_y y' + c_y z' = f_y \\frac{y'}{z'} + c_y$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6c8c02-28b9-4e11-94e0-9d237c8a0444",
   "metadata": {},
   "source": [
    "With $u$ and $v$ defined, we can express the $\\frac{\\partial w}{P'}$ analytically:\n",
    "$$\\frac{\\partial w}{P'} = - \\begin{pmatrix}\n",
    "\\frac{\\partial u}{x'} & \\frac{\\partial u}{y'} & \\frac{\\partial u}{z'} \\\\\n",
    "\\frac{\\partial v}{x'} & \\frac{\\partial v}{y'} & \\frac{\\partial v}{z'} \n",
    "\\end{pmatrix}$$\n",
    "\n",
    "This is simply a question of filling out coefficients:\n",
    "- $\\frac{\\partial u}{x'} = f_x / z'$\n",
    "- $\\frac{\\partial u}{y'} = 0$\n",
    "- $\\frac{\\partial u}{z'} = \\frac{-f_x x'}{z'^2}$: This comes from power law: $f(x) = x^r$, $f'(x) = r * x^{r-1}$. Applied to our case $f_x x' z'^{-1}$, it produces $-1 * f_x x' z'^{-2}$\n",
    "- $\\frac{\\partial v}{x'} = 0$\n",
    "- $\\frac{\\partial v}{y'} = f_y / z'$\n",
    "- $\\frac{\\partial v}{z'} = \\frac{-f_y y'}{z'^2}$: This comes from power law as above\n",
    "\n",
    "The minus sign in front of the matrix comes from the minus sign in the $w$: $m_p - (K \\cdot P') / s$.\n",
    "\n",
    "If we regroup:$$\\frac{\\partial w}{P'} = - \\begin{pmatrix}\n",
    "\\frac{f_x}{z'} & 0 & \\frac{-f_x x'}{z'^2} \\\\\n",
    "0 & \\frac{f_y}{z'} & \\frac{-f_y y'}{z'^2}\\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a72a4e-15cc-4b42-89d5-cbd91ef5b40f",
   "metadata": {},
   "source": [
    "Now that we have the first part of $\\frac{\\partial w}{d}$, we can start dealing with the second part $\\frac{\\partial P'}{d}$.\n",
    "\n",
    "Remember that $P' = T \\cdot P$ and that $T \\in SE(3)$. \n",
    "As one might recall from the Lie-Group-Algebra notebook, derivative of $SE(3)$ can be expressed through left perturbation like $d$ with:\n",
    "\n",
    "$$\\frac{\\partial(T \\cdot P)}{d} = \\lim_{\\delta \\to 0} \\frac{\\exp(\\gamma(\\delta)) \\exp(\\gamma(\\xi))P - \\exp(\\gamma(\\xi))P}{\\delta}$$\n",
    "where $\\xi$ is lie algebra of $T$ and $\\delta$ is lie algebra of $d$.\n",
    "\n",
    "We also know from the notebook that this expression reduces into:\n",
    "$$\\frac{\\partial(T \\cdot P)}{d} = \\begin{pmatrix} I & \\lambda(-(R\\cdot P+t)) \\\\ 0 & 0 \\end{pmatrix}$$\n",
    "This is a 4x6 matrix where $I \\in \\mathbb{R}^{3x3}$ and $\\lambda(-(R \\cdot P+t)) \\in \\mathbb{R}^{3x3}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f1fa72-5cb8-4a4a-9187-154a7bc0b062",
   "metadata": {},
   "source": [
    "The problem is we can't multiply the 2 by 3 matrix of $\\frac{\\partial w}{P'}$ with 4 by 6 matrix of $\\frac{\\partial P'}{d}$, due to mismatch of dimensions.\n",
    "However, upon a closer look, we see that last row of $\\frac{\\partial P'}{d}$ is composed of zeros.\n",
    "\n",
    "At this point we have 2 options. We can either pad the bottom of the first matrix with zeros or remove the last row from the second matrix. In both cases the end result would be the same. The multiplication of these matrices would produce a 2 by 6 matrix. Let's remove the last row from $\\frac{\\partial P'}{d}$ and write the multiplication. \n",
    "Remember that $R \\cdot P + t = P'$\n",
    "\n",
    "$$\\frac{\\partial w}{d} = \\frac{\\partial w}{P'} \\frac{\\partial P'}{d} = -\n",
    "\\begin{pmatrix}\n",
    "\\frac{f_x}{z'} & 0 & \\frac{-f_x x'}{z'^2} \\\\\n",
    "0 & \\frac{f_y}{z'} & \\frac{-f_y y'}{z'^2}\n",
    "\\end{pmatrix} \\cdot \\begin{pmatrix}\n",
    "1 & 0 & 0 & 0 & z' & -y' \\\\\n",
    "0 & 1 & 0 & -z' & 0 & x' \\\\\n",
    "0 & 0 & 1 & y' & -x' & 0 \\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d042c41a-539e-4ab6-b10a-6c53474bd08b",
   "metadata": {},
   "source": [
    "We have taken care of minimizing reprojection error with respect to camera pose part, but haven't touched on minimizing reprojection error with respect to spatial position.\n",
    "\n",
    "This requires us to take the derivative of $\\frac{\\partial w}{P}$ where $w$ is the error term and $P$ is the spatial position obtained through feature matching.\n",
    "\n",
    "Let $w = f_2(P) = k(q(P))$ where $q(P) = T \\cdot P = P'$ and \n",
    "$k(P') = m_p - (K \\cdot P') / s$, then\n",
    "$$f'_2(P) = \\frac{\\partial w}{P} = \\lim_{h \\to 0} \\frac{f_2(P + h) - f_2(P)}{h}$$\n",
    "From the chain rule: $f'_2(P) = k'(q(P)) q'(P)$\n",
    "Then the above equation is simply:\n",
    "$$\\frac{\\partial w}{P} = \\frac{\\partial w}{P'} \\frac{\\partial P'}{P}$$\n",
    "\n",
    "We already know the first part $\\frac{\\partial w}{P'} = -\\begin{pmatrix}\n",
    "\\frac{f_x}{z'} & 0 & \\frac{-f_x x'}{z'^2} \\\\\n",
    "0 & \\frac{f_y}{z'} & \\frac{-f_y y'}{z'^2}\\end{pmatrix}$.\n",
    "We just need to find $\\frac{\\partial P'}{P}$\n",
    "The equation $P' = R \\cdot P + t$ shows us that only $R$ is related to derivative:\n",
    "- From the power rule $R * 1 \\cdot P^{1 - 1}$ \n",
    "\n",
    "Hence the expression $\\frac{\\partial w}{P}$ reduces to:\n",
    "$$\\frac{\\partial w}{P} = \\begin{pmatrix}\n",
    "\\frac{f_x}{z'} & 0 & \\frac{-f_x x'}{z'^2} \\\\\n",
    "0 & \\frac{f_y}{z'} & \\frac{-f_y y'}{z'^2}\\end{pmatrix} \\cdot R$$\n",
    "This results in a 2 by 3 matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e21dbbe-a291-44da-ad24-97f5b18167ba",
   "metadata": {},
   "source": [
    "### RGB-D camera case: 3D - 3D Iterative Closest Point (ICP)\n",
    "\n",
    "We have two sets of 3d points:\n",
    "- $P = [p_1, p_2, \\dots, p_i, \\dots, p_n]$\n",
    "- $P' = [p'_1, p'_2, \\dots, p'_i, \\dots, p'_n]$\n",
    "\n",
    "We assume that these points are matched through features of images (as in the case of RGB-D images).\n",
    "We are looking for the transformation $T$ such that: \n",
    "$$P = [T \\cdot p'_1, T \\cdot p'_2, \\dots, T \\cdot p'_i, \\dots, T \\cdot p'_n]$$\n",
    "\n",
    "Notice that we don't use the intrinsic camera matrix anywhere here.\n",
    "This is essentially the same problem as PnP.\n",
    "\n",
    "The objective function for the minimization is:\n",
    "$err = (p_i - T \\cdot p'_i)^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7029e410-7e37-4843-9ad0-1a2517e1831e",
   "metadata": {},
   "source": [
    "Remember from the discussion in PnP that $T \\in SE(3)$. \n",
    "As one might recall from the Lie-Group-Algebra notebook, derivative of $SE(3)$ can be expressed through left perturbation like $d$ with:\n",
    "\n",
    "$$\\frac{\\partial(T \\cdot P)}{d} = \\lim_{\\delta \\to 0} \\frac{\\exp(\\gamma(\\delta)) \\exp(\\gamma(\\xi))P - \\exp(\\gamma(\\xi))P}{\\delta}$$\n",
    "where $\\xi$ is lie algebra of $T$ and $\\delta$ is lie algebra of $d$.\n",
    "\n",
    "We also know from the notebook that this expression reduces into:\n",
    "$$\\frac{\\partial(T \\cdot P)}{d} = \\begin{pmatrix} I & \\lambda(-(R\\cdot P+t)) \\\\ 0 & 0 \\end{pmatrix}$$\n",
    "This is a 4x6 matrix where $I \\in \\mathbb{R}^{3x3}$ and $\\lambda(-(R \\cdot P+t)) \\in \\mathbb{R}^{3x3}$\n",
    "\n",
    "Given the coefficient is negative for $T \\cdot p_i$ in $err = p_i - T \\cdot p'_i$, the $\\frac{err}{d}$ would be:\n",
    "$$\\frac{err}{d} = -\\begin{pmatrix} I & \\lambda(-(R\\cdot P+t)) \\\\ 0 & 0 \\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d5dfef-95ff-41a2-b9ab-b61ddd143444",
   "metadata": {},
   "source": [
    "## Pixel Brightness based Camera Motion Estimation\n",
    "\n",
    "Feature based methods are nice, but it takes a lot of time to calculate descriptors and match.\n",
    "Plus, features are sometimes hard to find in some cases. \n",
    "For example, when the camera is facing a white wall, it is likely that there are not enough features to provide an accurate enough estimation.\n",
    "\n",
    "Another possible solution is to use pixel intensity levels to estimate the camera pose matrix. \n",
    "Assuming the brightness level of a pixel doesn't change due to motion (this entirely false for certain surfaces like metals for example), we can use the intensity of a projected pixel as a target variable for the pose matrix that is being estimated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023b8377-7645-42ea-84d8-f32b29fb7451",
   "metadata": {},
   "source": [
    "Assuming that we are in completely still environment where lightining conditions never change, we can suppose that a pixel's brightness levels stay the same if they belong to the same location. \n",
    "This assumption can be formally stated as: $I_1(p_1) = I_2(p_2)$ where $p_1 = \\frac{K \\cdot P}{Z_1}$ and $p_2 = \\frac{K \\cdot (T \\cdot P )}{Z_2}$ and where $K$ is the intrinsic camera matrix and $P$ is the camera coordinate of the pixel. \n",
    "$I_1$ is the first image.\n",
    "$I_2$ is the second image. \n",
    "$T$ is the usual transformation matrix $T \\in SE(3)$.\n",
    "$Z_1$ is the z coordinate resulting from $K \\cdot P$ which is needed for perspective transformation and $Z_2$ is the z coordinate resulting from $K \\cdot (T \\cdot P)$.\n",
    "\n",
    "Notice that pixel brightness assumption is a very strong assumption, and it most definitely do not apply to certain surfaces like metals, mirrors etc, but it is a necessary assumption for the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1466c4d7-0c13-47e4-a5d3-d75dcdc1d129",
   "metadata": {},
   "source": [
    "We treat this version of the pose estimation problem as a non linear optimization problem where we try to minimize the **photometric** error.\n",
    "The photometric error is defined as\n",
    "$\\sum_{i=1}^k r_i(P_i, T)^2$ where \n",
    "$$r_i(P_i, T) = I_{1}(\\frac{K \\cdot P_i}{Z_i}) - I_{2}(\\frac{K \\cdot (T \\cdot P_i )}{Z_2})$$\n",
    "where $I_1$ represents the first image and $I_2$ represents the second image.\n",
    "As in the case of reprojection error, we can minimize this error function by making its derivative.\n",
    "Decomposing $r_i(P_i, T)$ as $r_i(P_i, T) = I_1(p_i) - I_2(g(h(P_i, T))$\n",
    "where $h(P_i, T) = T \\cdot P_i = u$ and $g(u) = \\frac{K \\cdot u}{Z_2}$, the derivative is $r_i'(P_i, T) = - I_2'(g(h(P_i, T))) g'(h(P_i, T)) h'(P_i, T)$ according to chain rule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b995e778-dd9e-46f8-920d-d3828907d51a",
   "metadata": {},
   "source": [
    "Given that $P_i$ is constant during the minimization algorithm, we can rewrite the $r_i'(P_i, T)$ as\n",
    "$$r_i'(T) = - I_2'(g(h(T))) g'(h(T)) h'(T)$$\n",
    "\n",
    "The $g'(h(T))$ is simply $$\\begin{pmatrix}\n",
    "\\frac{f_x}{z'} & 0 & \\frac{-f_x x'}{z'^2} \\\\\n",
    "0 & \\frac{f_y}{z'} & \\frac{-f_y y'}{z'^2}\\end{pmatrix}$$ as we had seen in the Mixed case section.\n",
    "\n",
    "The $h'(T)$ is simply $$\\begin{pmatrix} I & \\lambda(-(R\\cdot P+t)) \\\\ 0 & 0 \\end{pmatrix}$$ as we had seen in Mixed case section.\n",
    "This is a 4x6 matrix where $I \\in \\mathbb{R}^{3x3}$ and $\\lambda(-(R \\cdot P+t)) \\in \\mathbb{R}^{3x3}$\n",
    "\n",
    "As in the Mixed case we remove the last row and end up with a matrix $\\mathbb{R}^{2x6}$ after multiplication.\n",
    "\n",
    "The only thing new then is the gradient of the projected point in the second image: $I_2'(g(h(T)))$\n",
    "This is simply sum squared pixel differences in x and y directions.\n",
    "Formally: $grad(I) = \\sqrt{G_x(I)^2 + G_y(I)^2}$.\n",
    "\n",
    "This covers all the terms required for finding the first order derivative of the residual $r_i$ with respect to left perturbation of $T$, that is the jacobian of the residual:\n",
    "$$J(r_i) = - \\sqrt{G_x(I_2)_i^2 + G_y(I_2)_i^2} \\cdot \\begin{pmatrix}\n",
    "\\frac{f_x}{z'} & 0 & \\frac{-f_x x'}{z'^2} \\\\\n",
    "0 & \\frac{f_y}{z'} & \\frac{-f_y y'}{z'^2}\\end{pmatrix} \\cdot \\begin{pmatrix} I & \\lambda(-(R\\cdot P+t)) \\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbd3d83-2579-43b2-a0a4-b2b6c3f8f791",
   "metadata": {},
   "source": [
    "From the non linear optimization notebook, we know that:\n",
    "\n",
    "$$-k'(\\alpha^s) = k''(\\alpha^s) \\nabla \\alpha$$\n",
    "The $-k'(\\alpha^s)$ is the first order derivative of $k$ evaluated at $\\alpha^s$.\n",
    "The $k''(\\alpha^s)$ is the hessian matrix of $k$ evaluated at $\\alpha^s$.\n",
    "Hence the final form of the equation:\n",
    "$$-g(\\alpha^s) = H(\\alpha^s) \\nabla \\alpha$$\n",
    "\n",
    "The $k$ in our problem is $r_i(P_i, T)^2$.\n",
    "The $\\alpha^s$ is the parameter vector at $s$th iteration. \n",
    "The parameter vector in our case would be the lie algebra of the estimated pose matrix $T$.\n",
    "The $\\nabla \\alpha$ is the shift vector. The shift vector belongs to the same domain as parameter vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7626935f-58ae-4868-8d94-2373631e9e2f",
   "metadata": {},
   "source": [
    "# Bundle Adjustment and Sparsity of Hessian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfc3901-ad41-436e-bdb2-f8fe38e470ba",
   "metadata": {},
   "source": [
    "Here is the projection process of a point $p$:\n",
    "\n",
    "1. Transform $p = [X, Y, Z]$ in world space to camera space using transform matrix $T$: $P' = T \\cdot p = [X', Y', Z']$\n",
    "\n",
    "2. Transform $P'$ to normalized coordinates with perspective projection: $P_c = P' / Z' = [u, v, 1]$\n",
    "\n",
    "3. Apply the distortion model. For example radical distortion: \n",
    "- $u' = u (1 + k_1 r^2 + k_2 r^4)$\n",
    "- $v' = v (1 + k_1 r^2 + k_2 r^4)$\n",
    "\n",
    "4. Compute pixel coordinate $m = [u_s, v_s]$ using intrinsic camera properties:\n",
    "- $u_s = f_x u' + c_x$\n",
    "- $v_s = f_y v' + c_y$\n",
    "\n",
    "We can define this process as a single function $m = h(K, d, T, p)$. For multiple points, the process would something like:\n",
    "$$m_i = h(K, d, T_j, p_i)$$ where $i \\in \\{0, \\dots, N\\}$ and $j \\in \\{0, \\dots, M\\}$.\n",
    "\n",
    "Given that the intrinsic camera properties and lens distortion don't change, we can simplify this equation like: $m_i = k(T_j, p_i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb0770e-3510-4a58-b10d-b31fa09f8fb5",
   "metadata": {},
   "source": [
    "The cost function associated with the pixel would be $err(T_j, p_i) = m_i - k(T_j, p_i)$, overall cost function would be:\n",
    "$$\\sum_{j=1}^M \\sum_{i=1}^N = err(T_j, p_i)^2$$\n",
    "\n",
    "We had seen in the non linear optimization notebook that in order to minimize a residual function of the type $k(\\alpha) = err'(\\alpha)^2$, we need to use the following expression originating from using taylor expansion of $k(\\alpha)$:\n",
    "$$k(\\alpha^s + \\nabla \\alpha) \\approx k(\\alpha^s) + k'(\\alpha^s)\\nabla \\alpha + \\frac{k''(\\alpha^s)(\\nabla \\alpha)^2}{2!}$$\n",
    "\n",
    "From here we set the derivative of $k(\\alpha)$ to 0 and obtain the following expression:\n",
    "$$\\frac{\\partial k(\\alpha^s + \\nabla \\alpha)}{\\nabla \\alpha} = 0 =\n",
    "0 + k'(\\alpha^s)+ \\frac{2 * k''(\\alpha^s) \\nabla \\alpha}{2}$$\n",
    "\n",
    "The equation simplifies as:\n",
    "$$0 = k'(\\alpha^s) + k''(\\alpha^s) \\nabla \\alpha$$\n",
    "and consequently:\n",
    "$$-k'(\\alpha^s) = k''(\\alpha^s) \\nabla \\alpha$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2311eca9-3cb0-454b-947f-54f8367753c7",
   "metadata": {},
   "source": [
    "Now the bridge between $err(T_j, p_i)$ and $k$ is to realize that $\\alpha$ is just a vector incorporating $T_j$ and $p_i$, $\\alpha = [T_j, p_i]$ hence $\\alpha \\in R^9$ (remember that lie algebra of $T$ $\\mathbb{se}(3) \\in R^6$ and $p_i \\in R^3$). \n",
    "\n",
    "Consequently the $\\nabla \\alpha \\in R^9$ is also the case.\n",
    "The jacobian matrix resulting from $k'(\\alpha^s) = J(\\alpha^s)$ has also a peculiar structure. Assuming $\\mathbf{T} = \\{ T_0, \\dots, T_m \\}$ and $\\mathbf{p} = \\{p_0, \\dots, p_n\\}$\n",
    "\n",
    "$$J(\\alpha^s = [\\mathbf{T}, \\mathbf{p}]) = \\begin{pmatrix}\n",
    "\\frac{\\partial k_x}{\\partial T_0} & \\dots & \\frac{\\partial k_x}{\\partial T_m} & \\dots & \\frac{\\partial k_x}{\\partial p_0} & \\dots & \\frac{\\partial k_x}{\\partial p_n} \\\\\n",
    "\\frac{\\partial k_y}{\\partial T_0} & \\dots & \\frac{\\partial k_y}{\\partial T_m} & \\dots & \\frac{\\partial k_y}{\\partial p_0} & \\dots & \\frac{\\partial k_y}{\\partial p_n}\\end{pmatrix}$$\n",
    "where $k(\\alpha^s)= err(T, p): R^9 \\to R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177a7e58-c2df-4289-bf5b-d984efcf6a8f",
   "metadata": {},
   "source": [
    "It should be fairly apparent at this point that the jacobian can be cleanly divided into 2 sections: \n",
    "$$J(\\alpha^s) = \\begin{pmatrix} E & F \\end{pmatrix}$$\n",
    "where $E = \\begin{pmatrix}\n",
    "\\frac{\\partial k_x}{\\partial T_0} & \\dots & \\frac{\\partial k_x}{\\partial T_m} \\\\\n",
    "\\frac{\\partial k_y}{\\partial T_0} & \\dots & \\frac{\\partial k_y}{\\partial T_m}\\end{pmatrix}$ and $F = \\begin{pmatrix}\n",
    "\\frac{\\partial k_x}{\\partial p_0} & \\dots & \\frac{\\partial k_x}{\\partial p_n} \\\\\n",
    "\\frac{\\partial k_y}{\\partial p_0} & \\dots & \\frac{\\partial k_y}{\\partial p_n}\\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12083fe6-a2f0-459d-be81-68558cda6577",
   "metadata": {},
   "source": [
    "Now in practice, this matrix is incrementally built as one can recall from the applications:\n",
    "```c++\n",
    "  const int nb_iter = 10;\n",
    "  for (int i = 0; i < nb_iter; ++i) {\n",
    "    // H of H_f(\\alpha^k) \\nabla \\alpha\n",
    "    // which is approximated as (J_f(\\alpha^k)\n",
    "    // J^T(\\alpha^k)) = H\n",
    "    Eigen::Matrix<double, 6, 6> H =\n",
    "        Eigen::Matrix<double, 6, 6>::Zero();\n",
    "\n",
    "    // -J_f(\\alpha^k) f(\\alpha^k) = b\n",
    "    Vector6d b = Vector6d::Zero();\n",
    "\n",
    "    error = 0.0;\n",
    "\n",
    "    for (std::size_t k = 0; k < points_3d.size(); ++k) {\n",
    "      //\n",
    "      Eigen::Vector3d P_ = pose * points_3d[k];\n",
    "      Eigen::Vector2d error_k =\n",
    "          f(points_2d[k], P_);        // f(y_k, p_k);\n",
    "      error += error_k.squaredNorm(); // reprojection error\n",
    "      //\n",
    "      /**\n",
    "          j_f is the 2x6 jacobian matrix of the error\n",
    "         function f derived for the left perturbation of the\n",
    "         transformation matrix T (see camera motion ipynb\n",
    "         for explanation of its contents).\n",
    "         */\n",
    "      Eigen::Matrix<double, 2, 3> df_p =\n",
    "          get_f_delta_over_proj(P_);\n",
    "      Eigen::Matrix<double, 3, 6> df_d =\n",
    "          get_proj_delta_over_perturbation(P_);\n",
    "      Eigen::Matrix<double, 2, 6> J_f = df_p * df_d;\n",
    "\n",
    "      // using J_f we can approximate the H and grad_f\n",
    "      H += J_f.transpose() * J_f;\n",
    "      b += (-J_f.transpose()) * error_k;\n",
    "    }\n",
    "\n",
    "    // all the terms are accumulated now solve for \\nabla\n",
    "    // \\alpha\n",
    "    Vector6d nabla_alpha = solve_nabla_alpha(H, b);\n",
    "\n",
    "    // test terminal conditions\n",
    "    // numerical problems\n",
    "    if (std::isnan(nabla_alpha[0])) {\n",
    "      std::cout << \"result is nan\" << std::endl;\n",
    "      break;\n",
    "    }\n",
    "    //\n",
    "    // gradient problems\n",
    "    if ((i > 0) && (error >= lastError)) {\n",
    "      std::cout << \"error: \" << error\n",
    "                << \", last error: \" << lastError\n",
    "                << \", iteration: \" << i << std::endl;\n",
    "      break;\n",
    "    }\n",
    "    //\n",
    "    // perturb the pose matrix towards minimizing the\n",
    "    // reprojection error\n",
    "    pose = Sophus::SE3d::exp(nabla_alpha) * pose;\n",
    "    lastError = error;\n",
    "    std::cout << \"iteration \" << i\n",
    "              << \" cost=\" << std::cout.precision(12)\n",
    "              << error << std::endl;\n",
    "    if (nabla_alpha.norm() < 0.000001) {\n",
    "      // converge: see why in camera motion ipynb\n",
    "      break;\n",
    "    }\n",
    "  }\n",
    "```\n",
    "\n",
    "Notice the line `H += J_f.transpose() * J_f;`. \n",
    "We have point based jacobian that's being accumulated into hessian through gaussian approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1c54aa-4ae9-4e5d-b42a-a9c1d574bdba",
   "metadata": {},
   "source": [
    "Now theoratically, when we are computing the $k'(p_i, T_j)$ (which is a matrix), the gradient of all the other landmarks/points are 0.\n",
    "This makes the $k'(\\alpha^s)$ a very sparse matrix.\n",
    "Our jacobian had the form $J = [E, F]$, the hessian which is approximated as $H = J^T J$ would have the form:\n",
    "$H = \\begin{pmatrix} H_{11} & H_{12} \\\\ H_{21} & H_{22} \\end{pmatrix}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c317e132-9696-4e75-a5f6-1e3197fcfd5c",
   "metadata": {},
   "source": [
    "# Pose Graph Optimization\n",
    "\n",
    "State estimation is a costly process depending on how far you want remember and what you remember about the previous states.\n",
    "When you have real-time constraints, you can't keep considering all the previous landmarks as we had seen in Bundle Adjustment and Sparsity section.\n",
    "There are mainly 2 ways to deal with this problem:\n",
    "1. Keep N previous keyframes\n",
    "2. Leave landmarks alone and optimize only for pose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1958251-597b-4742-aba2-553a5a362612",
   "metadata": {},
   "source": [
    "The second approach is called optimizing a pose graph. \n",
    "Its main idea is to use the landmarks as constraints for optimizing pose, but not considering their residual function.\n",
    "\n",
    "Vertices of the pose graph optimization problem are camera poses. Edges of the pose graph optimization problem are relative motion between two vertices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6469170-3113-402b-9fa8-e3d2d810719e",
   "metadata": {},
   "source": [
    "Let $\\mathbb{T} = \\{T_1, T_2, \\dots, T_i, \\dots, T_n\\}$ be the set of poses which are effectively vertices of the pose graph.\n",
    "The relative motion from $T_i$ to $T_j$ would be $\\delta T_{ij}$ or shortly $T_{ij}$.\n",
    "Since $T$ is $SE(3)$ whose well defined operator is matrix multiplication.\n",
    "This relative motion can be defined as \n",
    "$T_{ij} = T^{-1}_i T_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8cdb5a-156b-424c-924f-d3ff02bee540",
   "metadata": {},
   "source": [
    "One can see that\n",
    "$$T_i T_{ij} = T_i T^{-1}_i T_j$$\n",
    "$$T_i T_{ij} = I T_j$$ where $I$ represents the identity matrix. \n",
    "From here it is easy to obtain $T_i T_{ij} = T_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6309b5-b9e5-4cdc-b4e5-56d80473c16d",
   "metadata": {},
   "source": [
    "Now assuming that we have a means to estimate $T_{ij}$ either through IMU or using optical flow, or some other way, we can use it as our error term, as in \n",
    "$$err_{ij} = T^{-1}_{ij} T^{-1}_i T_j$$\n",
    "The $T^{-1}_i T_j$ bit should be $T_{ij}$ in theory so the whole equation should be reduced to $I$ in theory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbba79e-c07f-458b-ba7f-7e89be5c8ebb",
   "metadata": {},
   "source": [
    "Similar to previous optimization problems, the way to minimize the error is to take the derivative of the residual/error function with respect to $T_i$ and to $T_j$ and set it to 0.\n",
    "\n",
    "We know from the Lie-Group-Algebra notebook that we can take the derivative of $SE(3)$ through left perturbation.\n",
    "Then the derivative of $err_{ij}$ at $T_i$ would go something like:\n",
    "$\\frac{\\partial err_{ij}}{T_i} = T_{ij}^{-1} \\Delta_{T_i} T_i^{-1} T_j$\n",
    "where $\\Delta_{T_i}$ is the perturbation term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f480c00-1d23-46df-b541-b3ed187b0570",
   "metadata": {},
   "source": [
    "The key here is to first transform the $T$ in $SE(3)$ group to their Lie algebra $\\mathbb{se}(3)$ form. \n",
    "In our equations let $\\zeta$ represent the Lie algebra $\\mathbb{se}(3)$ of $T$ in $SE(3)$.\n",
    "The relationship between $\\zeta$ and $T$ is\n",
    "$T = \\exp(\\gamma(\\zeta)) = \\begin{pmatrix}\n",
    "\\exp(\\lambda(\\phi)) & J \\rho \\\\ 0 & 1 \n",
    "\\end{pmatrix}$\n",
    "Please see the Lie-Group-Algebra notebook for $\\gamma$, $\\lambda$, $\\rho$, $\\phi$, $J$.\n",
    "\n",
    "The switch to algebra is necessary for derivation.\n",
    "In this form the error function can be written as\n",
    "$err_{ij} = \\exp(\\gamma(\\zeta)_{ij})^{-1} \\exp(\\gamma(\\zeta)_i)^{-1} \\exp(\\gamma(\\zeta))_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f966d4-f441-40b0-b72b-1746cf88c381",
   "metadata": {},
   "source": [
    "Since $\\gamma(\\zeta)$ is a matrix, the inverses reduce to coefficients as in:\n",
    "$exp(\\gamma(\\zeta)_{ij})^{-1} = \\exp(-\\gamma(\\zeta)_{ij})$ (Baker, 2006: p. 46)\n",
    "\n",
    "Then the derivative equation can be written as:\n",
    "$$\\frac{\\partial err_{ij}}{T_i} = \n",
    "    \\exp(-\\gamma(\\zeta)_{ij})\n",
    "    \\exp(\\gamma(\\zeta)_{\\Delta_{T_i}}\n",
    "    \\exp(-\\gamma(\\zeta)_{i})\n",
    "    \\exp(\\gamma(\\zeta)_j)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff8aa7a-8be4-497e-a092-a3681d9b58b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f132c7e2-f170-4bc9-8623-ede1ed7ea015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e65f25-ccd6-428b-8a00-ce4f0085cb28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d870fbd-8f6c-458e-a194-c0678c52c873",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[1] A. Baker, Matrix groups: an introduction to Lie group theory, 3. print. in Springer undergraduate mathematics series. London Berlin Heidelberg: Springer, 2006.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
